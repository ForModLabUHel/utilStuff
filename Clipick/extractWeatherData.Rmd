---
title: "extractWeatherData"
author: "Sofia Airola"
date: "27 3 2020"
output: html_document
---

```{r setup, include=FALSE, echo=TRUE}
# this is needed to run python inside R
library(reticulate)

# specify here the path of python in your computer
# the code works with python 2 but not with python 3
use_python("C:/Python27") 
```

```{python}
import cgitb
cgitb.enable()
import csv
import StringIO
import urllib2
import urllib
import time

def plus(a, b):
   return a+b

Longitude           = 8.385980
Latitude            = 48.255170
StartYear           = 1951 # Min=1951, Max=2100
StartMonth          = 1
StartDay            = 1
EndYear             = 2100
EndMonth            = 12
EndDay              = 31
IPCCAssessmentReport = 4 # either 4 or 5
Dataset             = 'METO-HC_HadRM3Q0_A1B_HadCM3Q0_DM_25km' # if IPCCAssessmentReport =4 use METO-HC_HadRM3Q0_A1B_HadCM3Q0_DM_25km. If IPCCAssessmentReport =5 use either knmihistorical, knmievaluation, knmircp45, knmircp85
 
 
 
#the file to export the output:
outFileName   = 'outputs/ClipickExportedData.csv' # tip you can build the name of the file to be according to the dates extracted
outFileHandle = open(outFileName, 'w')
 
 
start_time = time.time() # this is facultative, just to calculate timming of retrieval
 
# Build the HTTP REQUEST
pars = {}
pars['lat']        = Latitude
pars['lon']       = Longitude
pars['fmt']       = 'csv' # either csv, htmltable
pars['tspan']   = 'd'# d=daily; m =monthly
pars['sd']        = StartDay #'01'
pars['sm']       = StartMonth #'01'
pars['sy']         = StartYear
pars['ed']        = EndDay
pars['em']       = EndMonth
pars['ey']        = EndYear
pars['dts']       = Dataset# Beware of dates for extraction
pars['ar']         = IPCCAssessmentReport # either 4 or 5
pars['mod']     = "hisafe" # either yieldsafe or hisafe
url                    = 'http://www.isa.ulisboa.pt/proj/clipick/climaterequest_fast.php'
url_pars           = urllib.urlencode(pars)
full_url              = url + '?' + url_pars
print "Request made to " + full_url
response         = urllib2.urlopen(full_url)
the_page         = response.read()
 
f           = StringIO.StringIO(the_page)
reader = csv.reader(f, delimiter=',')
 
# CEATE AN ARRAY FROM THE REQUESTED CSV OUTPUT
result=[]
for row in reader:
    result.append(row)
 
# WRITE IT DOWN IN THE OUTPUT FILE
```
the daily output comes as
yieldsafe : Day, Month, Year, tas, rss, pr
hisafe    : Day, Month, Year, tasmax,tasmin,hursmax,hursmin,rss,pr,wss
in AR5 datasets, there are no min and max relative humidity (at the time of this deliverable).
therefore, at the moment, hisafe format for AR5 are as follows:
hisafe: : Day, Month, Year, tasmax,tasmin,hurs,evspsbl,rsds,pr,sfcWind
 
Currently Valid variables are (nomenclature as ENSEMBLES, and CORDEX project):
   "pr"     : precipitation
   "tas"    : Average Temperature
   "tasmin" : Minimum Temperature
   "tasmax" : Maximum temperature
   "rss"    : Radiation
   "evspsbl": Evaporation
   "hurs"   : Relative Humidity
   "hursmax": Maximum Relative humidity
   "hursmin": Minimum Relative humidity
   "wss"    : Wind Speed (ensembles)
   "sfcWind": Wind Speed (cordex)

```{python}
 
# WRITE THE RESULTS IN THE FILE AND CLOSE IT
print "Output is being written in " + outFileName
for i in result:
    outFileHandle.write(",".join(i) + "\n")
#outFileHandle.flush()
outFileHandle.close()
 
#Facultative...
end_time = time.time()
print "Processed in " + str(round(end_time - start_time,0)) + " seconds"
print "Output stored in " + outFileName
print "done"
```